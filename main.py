#!/usr/bin/env python3
import os
import asyncio
import configparser
from pathlib import Path
from typing import List, Set, Dict, Optional
import re
import logging
import gc
import sys
from datetime import datetime
from collections import defaultdict
from core import (
    SourceFetcher,
    PlaylistParser,
    AutoCategoryMatcher,
    SpeedTester,
    ResultExporter,
    Channel
)
from core.progress import SmartProgress

def print_start_page(config: configparser.ConfigParser, logger: logging.Logger):
    """æ‰“å°å¯åŠ¨é¡µé¢ï¼ˆå¸¦é…ç½®æ¦‚è§ˆï¼‰"""
    title = r"""
   ____   _   _   _       ___   _   _  __  __
  / ___| | \ | | | |     |_ _| | | | | \ \/ /
 | |     |  \| | | |      | |  | | | |  \  / 
 | |___  | |\  | | |___   | |  | |_| |  /  \ 
  \____| |_| \_| |_____| |___|  \___/  /_/\_\
                                             
    """
    
    # è·å–å…³é”®é…ç½®
    urls_path = config.get('PATHS', 'urls_path', fallback='config/urls.txt')
    templates_path = config.get('PATHS', 'templates_path', fallback='config/templates.txt')
    output_dir = config.get('MAIN', 'output_dir', fallback='outputs')
    uncategorized_path = config.get('PATHS', 'uncategorized_channels_path', fallback='config/uncategorized.txt')
    blacklist_path = config.get('BLACKLIST', 'blacklist_path', fallback='config/blacklist.txt')
    whitelist_path = config.get('WHITELIST', 'whitelist_path', fallback='config/whitelist.txt')
    failed_urls_path = config.get('PATHS', 'failed_urls_path', fallback='config/failed_urls.txt')
    log_file_path = config.get('LOGGING', 'log_file_path', fallback='outputs/debug.log')
    
    fetcher_timeout = config.getfloat('FETCHER', 'timeout', fallback=15)
    fetcher_concurrency = config.getint('FETCHER', 'concurrency', fallback=5)
    tester_timeout = config.getfloat('TESTER', 'timeout', fallback=10)
    tester_concurrency = config.getint('TESTER', 'concurrency', fallback=8)
    enable_history = config.getboolean('EXPORTER', 'enable_history', fallback=False)
    log_level = config.get('LOGGING', 'log_level', fallback='INFO').upper()
    
    # è·å–ç‰ˆæœ¬ä¿¡æ¯
    try:
        from core import __version__
        version = f"v{__version__}"
    except ImportError:
        version = "v1.0.0"
    
    # æ„å»ºå¯åŠ¨ä¿¡æ¯
    start_info = f"""
{title}
â•”â•”â•”â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—â•—â•—â•—
â•‘â•‘â•‘â•‘ IPTVæ™ºèƒ½å¤„ç†ç³»ç»Ÿ {version}                          â•‘â•‘â•‘â•‘â•‘â•‘â•‘
â•‘â•‘â•‘â•‘ å¯åŠ¨æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}                    â•‘â•‘â•‘â•‘â•‘â•‘â•‘
â•Ÿâ•Ÿâ•Ÿâ•Ÿâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¢â•¢â•¢â•¢
â•Ÿâ•Ÿâ•Ÿâ•Ÿâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¢â•¢â•¢â•¢
â•‘â•‘â•‘â•‘ å¤„ç†æµç¨‹:                                        â•‘â•‘â•‘â•‘â•‘â•‘â•‘
â•‘â•‘â•‘â•‘   1. è·å–è®¢é˜…æº â†’ 2. è§£æé¢‘é“ â†’ 3. å»é‡          â•‘â•‘â•‘â•‘â•‘â•‘â•‘
â•‘â•‘â•‘â•‘   4. é»‘åå•è¿‡æ»¤ â†’ 5. æ™ºèƒ½åˆ†ç±» â†’ 6. æµ‹é€Ÿæµ‹è¯•      â•‘â•‘â•‘â•‘â•‘â•‘â•‘
â•‘â•‘â•‘â•‘   7. ç»“æœå¯¼å‡º â†’ 8. å®Œæˆ!                         â•‘â•‘â•‘â•‘â•‘â•‘â•‘
â•šâ•šâ•šâ•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
æ ¸å¿ƒé…ç½®æ¦‚è§ˆ:                                    
â€¢ è®¢é˜…æºè·¯å¾„: {urls_path:<25} 
â€¢ åˆ†ç±»æ¨¡æ¿: {templates_path:<25} 
â€¢ æœªåˆ†ç±»é¢‘é“è·¯å¾„: {uncategorized_path:<25}
â€¢ é»‘åå•è·¯å¾„: {blacklist_path:<25}
â€¢ ç™½åå•è·¯å¾„: {whitelist_path:<25}
â€¢ å¤±è´¥URLè·¯å¾„: {failed_urls_path:<25}
â€¢ æ—¥å¿—æ–‡ä»¶è·¯å¾„: {log_file_path:<25}
â€¢ è¾“å‡ºç›®å½•: {output_dir:<25} 
â€¢ æŠ“å–å¹¶å‘æ•°: {fetcher_concurrency:<3} è¶…æ—¶: {fetcher_timeout:<4}ç§’ 
â€¢ æµ‹é€Ÿå¹¶å‘æ•°: {tester_concurrency:<3} è¶…æ—¶: {tester_timeout:<4}ç§’ 
â€¢ å†å²è®°å½•: {'å¯ç”¨' if enable_history else 'ç¦ç”¨':<8}          
â€¢ æ—¥å¿—çº§åˆ«: {log_level:<8}                     

"""
    
    # æ‰“å°åˆ°æ—¥å¿—å’Œæ§åˆ¶å°
    if logger:
        logger.info(start_info)
    else:
        print(start_info)

def setup_logging(config: configparser.ConfigParser) -> Optional[logging.Logger]:
    """é…ç½®æ—¥å¿—ç³»ç»Ÿï¼ˆæ¯æ¬¡è¿è¡Œè¦†ç›–æ—¥å¿—æ–‡ä»¶ï¼‰"""
    enable_logging = config.getboolean('LOGGING', 'enable_logging', fallback=True)
    if not enable_logging:
        logging.disable(logging.CRITICAL)
        return None

    log_level = config.get('LOGGING', 'log_level', fallback='INFO').upper()
    log_to_file = config.getboolean('LOGGING', 'log_to_file', fallback=False)

    logger = logging.getLogger()
    logger.setLevel(log_level)

    # æ¸…é™¤æ‰€æœ‰ç°æœ‰å¤„ç†å™¨
    for handler in logger.handlers[:]:
        logger.removeHandler(handler)

    # æ§åˆ¶å°å¤„ç†å™¨ï¼ˆå§‹ç»ˆæ·»åŠ ï¼‰
    console_handler = logging.StreamHandler()
    console_formatter = logging.Formatter(
        '%(asctime)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    console_handler.setFormatter(console_formatter)
    logger.addHandler(console_handler)

    # æ–‡ä»¶å¤„ç†å™¨ï¼ˆè¦†ç›–æ¨¡å¼ï¼‰
    if log_to_file:
        log_file = Path(config.get('LOGGING', 'log_file_path', fallback='outputs/debug.log'))
        log_file.parent.mkdir(parents=True, exist_ok=True)
        file_handler = logging.FileHandler(log_file, mode='w', encoding='utf-8')
        file_formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        file_handler.setFormatter(file_formatter)
        logger.addHandler(file_handler)
    
    return logger

def is_blacklisted(channel: Channel, blacklist: Set[str]) -> bool:
    """æ£€æŸ¥é¢‘é“æ˜¯å¦åœ¨é»‘åå•ä¸­"""
    channel_name = channel.name.lower()
    channel_url = channel.url.lower()
    
    for entry in blacklist:
        if '*' in entry:
            if entry.startswith('*.'):
                suffix = entry[2:].lower()
                if channel_url.endswith(suffix) or channel_name.endswith(suffix):
                    return True
        elif entry in channel_name or entry in channel_url:
            return True
    return False

async def main():
    """ä¸»å·¥ä½œæµç¨‹ï¼ˆå¸¦å¯åŠ¨é¡µé¢ï¼‰"""
    logger = None  # å…³é”®ä¿®å¤ï¼šç¡®ä¿loggerå˜é‡å§‹ç»ˆå­˜åœ¨
    
    try:
        # åˆå§‹åŒ–é…ç½®
        config = configparser.ConfigParser()
        config_path = Path('config/config.ini')
        if not config_path.exists():
            raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        config.read(config_path, encoding='utf-8')

        # è®¾ç½®æ—¥å¿—ï¼ˆè¦†ç›–æ¨¡å¼ï¼‰
        logger = setup_logging(config)
        
        # æ‰“å°å¯åŠ¨é¡µé¢
        print_start_page(config, logger)

        # åˆå§‹åŒ–è¾“å‡ºç›®å½•
        output_dir = Path(config.get('MAIN', 'output_dir', fallback='outputs'))
        output_dir.mkdir(parents=True, exist_ok=True)

        # åŠ è½½é»‘åå•å’Œç™½åå•
        blacklist = set()
        whitelist = set()
        
        blacklist_path = Path(config.get('BLACKLIST', 'blacklist_path', fallback='config/blacklist.txt'))
        if blacklist_path.exists():
            with open(blacklist_path, 'r', encoding='utf-8') as f:
                blacklist = {line.strip().lower() for line in f if line.strip() and not line.startswith('#')}

        whitelist_path = Path(config.get('WHITELIST', 'whitelist_path', fallback='config/whitelist.txt'))
        if whitelist_path.exists():
            with open(whitelist_path, 'r', encoding='utf-8') as f:
                whitelist = {line.strip().lower() for line in f if line.strip() and not line.startswith('#')}

        # ==================== é˜¶æ®µ1: è·å–è®¢é˜…æº ====================
        urls_path = Path(config.get('PATHS', 'urls_path', fallback='config/urls.txt'))
        try:
            if not urls_path.exists():
                raise FileNotFoundError(f"è®¢é˜…æºæ–‡ä»¶ä¸å­˜åœ¨: {urls_path}")
            
            logger.info(f"ğŸ“¡ğŸ“¡ å¼€å§‹è·å–è®¢é˜…æº | è·¯å¾„: {urls_path}")
            
            with open(urls_path, 'r', encoding='utf-8') as f:
                urls = [line.strip() for line in f if line.strip()]
                logger.debug(f"è¯»å–åˆ° {len(urls)} ä¸ªè®¢é˜…æºURL | ç¤ºä¾‹: {urls[:3]}...")
                
            if not urls:
                raise ValueError("è®¢é˜…æºåˆ—è¡¨ä¸ºç©ºï¼Œè¯·æ£€æŸ¥urls.txtæ–‡ä»¶å†…å®¹")
                
            fetcher = SourceFetcher(
                timeout=config.getfloat('FETCHER', 'timeout', fallback=15),
                concurrency=config.getint('FETCHER', 'concurrency', fallback=5),
                config=config
            )
            
            # å¸¦é‡è¯•æœºåˆ¶çš„è·å–ï¼ˆå›ºå®šé‡è¯•2æ¬¡ï¼‰
            contents = []
            for attempt in range(1, 3):  # ä¸æ–°å¢é…ç½®é¡¹ï¼Œå›ºå®šé‡è¯•2æ¬¡
                try:
                    fetch_progress = SmartProgress(len(urls), f"è·å–è®¢é˜…æº(å°è¯•{attempt}/2)")
                    contents = await fetcher.fetch_all(urls, fetch_progress.update)
                    fetch_progress.complete()
                    break
                except Exception as e:
                    if attempt == 2:
                        raise
                    logger.warning(f"ç¬¬ {attempt} æ¬¡è·å–å¤±è´¥: {str(e)}")
                    await asyncio.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
                    
            # ç»Ÿè®¡æœ‰æ•ˆå†…å®¹
            valid_contents = [c for c in contents if c and c.strip()]
            logger.info(
                f"âœ… è®¢é˜…æºè·å–å®Œæˆ | æ€»æ•°: {len(urls)} | æˆåŠŸ: {len(valid_contents)} "
                f"({len(valid_contents)/len(urls)*100:.1f}%)"
            )
            
        except Exception as e:
            logger.error(f"â€¼ï¸ è®¢é˜…æºè·å–é˜¶æ®µå¤±è´¥: {str(e)}", exc_info=True)
            raise

        # ==================== é˜¶æ®µ2: è§£æé¢‘é“ ====================
        try:
            parser = PlaylistParser(config)
            all_channels = []
            total_channels = 0
            
            logger.info(f"ğŸ”ğŸ” å¼€å§‹è§£æé¢‘é“å†…å®¹ | æœ‰æ•ˆè®¢é˜…æº: {len(valid_contents)}")
            
            parse_progress = SmartProgress(len(valid_contents), "è§£æé¢‘é“")
            for i, content in enumerate(valid_contents, 1):
                try:
                    channels = list(parser.parse(content))
                    all_channels.extend(channels)
                    total_channels += len(channels)
                    
                    # æ¯è§£æ10ä¸ªæºæˆ–5000ä¸ªé¢‘é“æ—¶è¾“å‡ºè¿›åº¦
                    if i % 10 == 0 or len(all_channels) % 5000 == 0:
                        logger.debug(
                            f"è§£æè¿›åº¦ | æº: {i}/{len(valid_contents)} "
                            f"| é¢‘é“: {len(all_channels)} "
                            f"| æœ€æ–°: {channels[-1].name if channels else 'N/A'}"
                        )
                        gc.collect()
                        
                    parse_progress.update()
                except Exception as e:
                    logger.error(f"è§£æå¼‚å¸¸(æº#{i}): {str(e)}")
                    continue
                    
            parse_progress.complete()
            
            # è§£æç»“æœç»Ÿè®¡
            unique_sources = len({c.url for c in all_channels})
            logger.info(
                f"âœ… é¢‘é“è§£æå®Œæˆ | æ€»é¢‘é“æ•°: {len(all_channels)} "
                f"| å”¯ä¸€æº: {unique_sources} "
                f"| é‡å¤ç‡: {(1 - unique_sources/len(all_channels))*100:.1f}%"
            )
            
        except Exception as e:
            logger.error(f"â€¼ï¸ é¢‘é“è§£æé˜¶æ®µå¤±è´¥: {str(e)}", exc_info=True)
            raise

        # ==================== é˜¶æ®µ3: å»é‡ ====================
        duplicate_progress = SmartProgress(len(all_channels), "å»é‡å¤„ç†")
        unique_channels = {channel.url: channel for channel in all_channels}
        duplicate_progress.update(len(all_channels))
        unique_channels = list(unique_channels.values())
        duplicate_progress.complete()
        logger.info(f"å»é‡å®Œæˆ | åŸå§‹: {len(all_channels)} | å»é‡å: {len(unique_channels)}")

        # ==================== é˜¶æ®µ4: é»‘åå•è¿‡æ»¤ ====================
        filter_progress = SmartProgress(len(unique_channels), "é»‘åå•è¿‡æ»¤")
        filtered_channels = [
            channel for channel in unique_channels
            if not is_blacklisted(channel, blacklist)
        ]
        filter_progress.update(len(unique_channels))
        filter_progress.complete()
        logger.info(f"é»‘åå•è¿‡æ»¤å®Œæˆ | è¿‡æ»¤å‰: {len(unique_channels)} | è¿‡æ»¤å: {len(filtered_channels)}")

        # ==================== é˜¶æ®µ5: æ™ºèƒ½åˆ†ç±» ====================
        templates_path = Path(config.get('PATHS', 'templates_path', fallback='config/templates.txt'))
        if not templates_path.exists():
            raise FileNotFoundError(f"åˆ†ç±»æ¨¡æ¿ä¸å­˜åœ¨: {templates_path}")
        
        matcher = AutoCategoryMatcher(str(templates_path), config)
        classify_progress = SmartProgress(len(filtered_channels), "åˆ†ç±»å¤„ç†")
        
        # æ‰¹é‡åŒ¹é…åˆ†ç±»
        category_mapping = matcher.batch_match([c.name for c in filtered_channels])
        
        processed_channels = []
        for channel in filtered_channels:
            channel.category = category_mapping[channel.name]
            channel.name = matcher.normalize_channel_name(channel.name)
            processed_channels.append(channel)
            classify_progress.update()
            if len(processed_channels) % 5000 == 0:
                gc.collect()
        
        classify_progress.complete()
        logger.info(f"åˆ†ç±»å®Œæˆ | å·²åˆ†ç±»: {len([c for c in processed_channels if c.category != 'æœªåˆ†ç±»'])} | æœªåˆ†ç±»: {len(processed_channels) - len([c for c in processed_channels if c.category != 'æœªåˆ†ç±»'])}")

        # ==================== é˜¶æ®µ6: æµ‹é€Ÿæµ‹è¯• ====================
        tester = SpeedTester(
            timeout=config.getfloat('TESTER', 'timeout', fallback=10),
            concurrency=config.getint('TESTER', 'concurrency', fallback=8),
            max_attempts=config.getint('TESTER', 'max_attempts', fallback=2),
            min_download_speed=config.getfloat('TESTER', 'min_download_speed', fallback=0.1),
            enable_logging=config.getboolean('TESTER', 'enable_logging', fallback=True),
            config=config
        )
        
        # æŒ‰æ¨¡æ¿æ’åº
        sorted_channels = matcher.sort_channels_by_template(processed_channels, whitelist)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰é¢‘é“éœ€è¦æµ‹é€Ÿ
        if not sorted_channels:
            logger.warning("âš ï¸ æ²¡æœ‰éœ€è¦æµ‹é€Ÿçš„é¢‘é“ï¼Œè·³è¿‡æµ‹é€Ÿé˜¶æ®µ")
        else:
            # åˆ†æ‰¹æµ‹é€Ÿ
            batch_size = min(5000, len(sorted_channels))
            batch_size = max(1, batch_size)
            
            test_progress = SmartProgress(len(sorted_channels), "æµ‹é€Ÿæµ‹è¯•")
            failed_urls = set()

            for i in range(0, len(sorted_channels), batch_size):
                batch = sorted_channels[i:i+batch_size]
                await tester.test_channels(batch, test_progress.update, failed_urls, whitelist)
                del batch
                gc.collect()
            
            test_progress.complete()
            logger.info(f"æµ‹é€Ÿå®Œæˆ | æ€»æ•°: {len(sorted_channels)} | å¤±è´¥: {len(failed_urls)}")

        # ==================== é˜¶æ®µ7: ç»“æœå¯¼å‡º ====================
        exporter = ResultExporter(
            output_dir=str(output_dir),
            template_path=str(templates_path),
            config=config,
            matcher=matcher
        )
        
        export_progress = SmartProgress(1, "å¯¼å‡ºç»“æœ")
        exporter.export(sorted_channels, whitelist, export_progress.update)
        export_progress.complete()

        # å®Œæˆæç¤º
        online = sum(1 for c in sorted_channels if c.status == 'online') if sorted_channels else 0
        total = len(sorted_channels) if sorted_channels else 0
        logger.info(f"ğŸ‰ğŸ‰ ä»»åŠ¡å®Œæˆ! åœ¨çº¿é¢‘é“: {online}/{total} | æˆåŠŸç‡: {online/total*100:.1f}%")

    except Exception as e:
        # å®‰å…¨å¼‚å¸¸å¤„ç†
        if logger:  
            logger.error(f"â€¼ï¸ å‘ç”Ÿä¸¥é‡é”™è¯¯: {str(e)}", exc_info=True)
        else:
            print(f"â€¼ï¸ å‘ç”Ÿä¸¥é‡é”™è¯¯: {str(e)}")
        sys.exit(1)

if __name__ == "__main__":
    # Windowsç³»ç»Ÿè®¾ç½®äº‹ä»¶å¾ªç¯ç­–ç•¥
    if os.name == 'nt':
        from asyncio import WindowsSelectorEventLoopPolicy
        asyncio.set_event_loop_policy(WindowsSelectorEventLoopPolicy())

    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nğŸ›‘ğŸ›‘ğŸ›‘ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(0)
    except Exception as e:
        print(f"ğŸ’¥ğŸ’¥ å…¨å±€å¼‚å¸¸: {str(e)}")
        sys.exit(1)