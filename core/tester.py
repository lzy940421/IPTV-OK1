import asyncio
import aiohttp
import time
import logging
from typing import List, Set, Tuple, Optional, Callable
from configparser import ConfigParser
from pathlib import Path
from .models import Channel

logger = logging.getLogger(__name__)

class SpeedTester:
    """HTTPæµ‹é€Ÿå¼•æ“Žï¼ˆå®Œæ•´æ”¯æŒå¤±è´¥URLè®°å½•ï¼‰"""

    def __init__(self, 
                 timeout: float, 
                 concurrency: int, 
                 max_attempts: int,
                 min_download_speed: float, 
                 enable_logging: bool = True,
                 config: Optional[ConfigParser] = None):
        self.timeout = timeout
        self.concurrency = max(1, concurrency)
        self.max_attempts = max(1, max_attempts)
        self.min_download_speed = min_download_speed
        self._enable_logging = enable_logging
        self.config = config or ConfigParser()
        self.max_latency = self.config.getfloat('TESTER', 'max_latency', fallback=1000.0)
        self._init_logger()
        self.semaphore = asyncio.BoundedSemaphore(self.concurrency)
        self.success_count = 0
        self.total_count = 0
        self.start_time = 0.0

    def _init_logger(self):
        self.logger = logging.getLogger('core.tester')
        self.logger.disabled = not self._enable_logging
        self.log = self._create_log_method()

    def _create_log_method(self):
        def make_log_method(level):
            def log_method(msg, *args, **kwargs):
                if self._enable_logging:
                    getattr(self.logger, level)(msg, *args, **kwargs)
            return log_method
        
        return type('LogMethod', (), {
            'debug': make_log_method('debug'),
            'info': make_log_method('info'),
            'warning': make_log_method('warning'),
            'error': make_log_method('error'),
            'exception': make_log_method('exception')
        })

    async def test_channels(self, 
                          channels: List[Channel], 
                          progress_cb: Callable,
                          failed_urls: Set[str], 
                          white_list: Set[str]) -> None:
        """æ‰¹é‡æµ‹è¯•HTTPé¢‘é“ï¼ˆè‡ªåŠ¨è®°å½•å¤±è´¥URLï¼‰"""
        self.total_count = len(channels)
        self.success_count = 0
        self.start_time = time.time()
        
        self.log.info(
            "â–¶ï¸ å¼€å§‹æµ‹é€Ÿ | æ€»æ•°: %d | å¹¶å‘: %d | å»¶è¿Ÿé˜ˆå€¼: %.0fms | æœ€ä½Žé€Ÿåº¦: %.1fKB/s",
            self.total_count, self.concurrency, self.max_latency, self.min_download_speed
        )

        connector = aiohttp.TCPConnector(
            limit=self.concurrency,
            force_close=False,
            enable_cleanup_closed=True,
            ssl=False
        )

        try:
            async with aiohttp.ClientSession(
                connector=connector,
                timeout=aiohttp.ClientTimeout(total=self.timeout)
            ) as session:
                tasks = [
                    self._test_single_channel(session, channel, progress_cb, failed_urls, white_list)
                    for channel in channels
                ]
                await asyncio.gather(*tasks)
        except Exception as e:
            self.log.error("æµ‹é€Ÿè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: %s", str(e))
            raise
        finally:
            await connector.close()
            
            # ä¿å­˜å¤±è´¥URLåˆ°é…ç½®æ–‡ä»¶æŒ‡å®šè·¯å¾„
            if failed_urls:
                failed_path = Path(self.config.get(
                    'PATHS', 
                    'failed_urls_path', 
                    fallback='config/failed_urls.txt'
                ))
                failed_path.parent.mkdir(parents=True, exist_ok=True)
                
                with open(failed_path, 'w', encoding='utf-8') as f:
                    f.writelines(f"{url}\n" for url in failed_urls)
                
                self.log.info(f"å¤±è´¥URLå·²ä¿å­˜åˆ°: {failed_path.absolute()}")

        elapsed = time.time() - self.start_time
        success_rate = (self.success_count / self.total_count) * 100 if self.total_count > 0 else 0
        self.log.info(
            "âœ… æµ‹é€Ÿå®Œæˆ | æˆåŠŸ: %d(%.1f%%) | å¤±è´¥: %d | ç”¨æ—¶: %.1fs",
            self.success_count, success_rate,
            self.total_count - self.success_count,
            elapsed
        )

    async def _test_single_channel(self,
                                 session: aiohttp.ClientSession,
                                 channel: Channel,
                                 progress_cb: Callable,
                                 failed_urls: Set[str],
                                 white_list: Set[str]) -> None:
        async with self.semaphore:
            if self._is_in_white_list(channel, white_list):
                channel.status = 'online'
                self.log.debug("ðŸŸ¢ ç™½åå•è·³è¿‡ %s", channel.name)
                progress_cb()
                return

            for attempt in range(1, self.max_attempts + 1):
                try:
                    success, speed, latency = await self._unified_test(session, channel)
                    if success:
                        self._handle_success(channel, speed, latency)
                        break
                    elif attempt == self.max_attempts:
                        self._handle_failure(channel, failed_urls, speed, latency)
                except Exception as e:
                    if attempt == self.max_attempts:
                        self._handle_error(channel, failed_urls, e)
                finally:
                    if attempt == self.max_attempts:
                        progress_cb()

    async def _unified_test(self,
                          session: aiohttp.ClientSession,
                          channel: Channel) -> Tuple[bool, float, float]:
        try:
            headers = {'User-Agent': 'Mozilla/5.0'}
            
            # æµ‹å»¶è¿Ÿ
            latency_start = time.perf_counter()
            async with session.head(channel.url, headers=headers, timeout=self.timeout) as resp:
                latency = (time.perf_counter() - latency_start) * 1000
                if latency > self.max_latency or resp.status != 200:
                    return False, 0.0, latency

            # æµ‹é€Ÿåº¦
            start = time.perf_counter()
            content_size = 0
            async with session.get(channel.url, headers=headers, timeout=self.timeout) as resp:
                async for chunk in resp.content.iter_chunked(1024 * 4):
                    content_size += len(chunk)
                
                duration = time.perf_counter() - start
                speed = content_size / duration / 1024 if duration > 0 else 0
                return speed >= self.min_download_speed, speed, latency

        except (asyncio.TimeoutError, aiohttp.ClientError):
            return False, 0.0, 0.0
        except Exception as e:
            self.log.error("æµ‹è¯•é”™è¯¯ %s: %s", channel.url, str(e)[:100])
            return False, 0.0, 0.0

    def _handle_success(self, channel: Channel, speed: float, latency: float):
        self.success_count += 1
        channel.status = 'online'
        channel.response_time = latency
        channel.download_speed = speed
        self.log.info(
            "âœ… æˆåŠŸ | %-30s | %6.1fKB/s | %4.0fms | %s",
            channel.name[:30], speed, latency, self._simplify_url(channel.url)
        )

    def _handle_failure(self, channel: Channel, failed_urls: Set[str], speed: float, latency: float):
        failed_urls.add(channel.url)
        channel.status = 'offline'
        reason = "é€Ÿåº¦ä¸è¶³" if speed > 0 else "å»¶è¿Ÿè¿‡é«˜" if latency > 0 else "è¿žæŽ¥å¤±è´¥"
        self.log.warning(
            "âŒ å¤±è´¥ | %-30s | %6.1fKB/s | %4.0fms | %-8s | %s",
            channel.name[:30], speed, latency, reason, self._simplify_url(channel.url)
        )

    def _handle_error(self, channel: Channel, failed_urls: Set[str], error: Exception):
        failed_urls.add(channel.url)
        channel.status = 'offline'
        self.log.error(
            "â€¼ï¸ å¼‚å¸¸ | %-30s | %-20s | %s",
            channel.name[:30], str(error)[:20], self._simplify_url(channel.url)
        )

    def _simplify_url(self, url: str) -> str:
        return url[:100] + '...' if len(url) > 100 else url

    def _is_in_white_list(self, channel: Channel, white_list: Set[str]) -> bool:
        return channel.name.lower() in white_list if white_list else False