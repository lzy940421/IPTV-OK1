import asyncio
import aiohttp
import time
import re
import logging
from typing import List, Set, Tuple, Optional, Dict, Callable
from collections import defaultdict
from urllib.parse import urlparse
from configparser import ConfigParser
from .models import Channel

logger = logging.getLogger(__name__)

class SpeedTester:
    """é«˜æ€§èƒ½æµåª’ä½“æµ‹é€Ÿå¼•æ“ï¼ˆå®Œæ•´ä¼˜åŒ–ç‰ˆï¼‰"""

    def __init__(self, 
                 timeout: float, 
                 concurrency: int, 
                 max_attempts: int,
                 min_download_speed: float, 
                 enable_logging: bool = True,
                 config: Optional[ConfigParser] = None):
        """
        åˆå§‹åŒ–æµ‹é€Ÿå™¨
        
        å‚æ•°:
            timeout: åŸºç¡€è¶…æ—¶æ—¶é—´(ç§’)
            concurrency: æœ€å¤§å¹¶å‘æ•°
            max_attempts: æœ€å¤§é‡è¯•æ¬¡æ•°
            min_download_speed: HTTPæœ€ä½é€Ÿåº¦è¦æ±‚(KB/s)
            enable_logging: æ˜¯å¦å¯ç”¨æ—¥å¿—
            config: é…ç½®å¯¹è±¡
        """
        # åŸºç¡€é…ç½®
        self.timeout = timeout
        self.concurrency = max(1, concurrency)
        self.max_attempts = max(1, max_attempts)
        self.min_download_speed = max(0.1, min_download_speed)
        self._enable_logging = enable_logging
        self.config = config or ConfigParser()

        # æ–°å¢ä¸‹è½½å¤§å°é™åˆ¶é…ç½®
        self.max_download_size = self.config.getint(
            'TESTER', 
            'max_download_size', 
            fallback=100 * 1024  # é»˜è®¤100KB
        )
        
        # åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ
        self._init_logger()

        # åè®®æ£€æµ‹
        self.rtp_udp_pattern = re.compile(r'/(rtp|udp)/', re.IGNORECASE)
        
        # åè®®ç‰¹å®šé…ç½®
        self.udp_timeout = self.config.getfloat('TESTER', 'udp_timeout', fallback=max(0.5, timeout * 0.3))
        self.http_timeout = self.config.getfloat('TESTER', 'http_timeout', fallback=timeout)
        self.min_udp_download_speed = self.config.getfloat('TESTER', 'min_udp_download_speed', fallback=30)
        self.max_udp_latency = self.config.getint('TESTER', 'max_udp_latency', fallback=300)
        self.max_http_latency = self.config.getint('TESTER', 'max_http_latency', fallback=1000)
        self.max_channels_per_ip = self.config.getint('TESTER', 'max_channels_per_ip', fallback=100)
        
        # IPé˜²æŠ¤æœºåˆ¶
        self.failed_ips: Dict[str, int] = defaultdict(int)
        self.max_failures_per_ip = self.config.getint('PROTECTION', 'max_failures_per_ip', fallback=5)
        self.blocked_ips: Set[str] = set()
        self.ip_cooldown: Dict[str, float] = {}  # IPå†·å´æ—¶é—´è®°å½•
        self.min_ip_interval = self.config.getfloat('PROTECTION', 'min_ip_interval', fallback=0.5)
        
        # å¹¶å‘æ§åˆ¶
        self.semaphore = asyncio.BoundedSemaphore(self.concurrency)
        
        # ç»Ÿè®¡
        self.success_count = 0
        self.total_count = 0
        self.start_time = 0.0

    def _init_logger(self):
        """åˆå§‹åŒ–æ—¥å¿—è®°å½•å™¨"""
        self.logger = logging.getLogger('core.tester')
        self.logger.disabled = not self._enable_logging
        
        # åˆ›å»ºå®‰å…¨çš„æ—¥å¿—æ–¹æ³•
        self.log = self._create_log_method()

    def _create_log_method(self):
        """åˆ›å»ºå¸¦å¼€å…³çš„æ—¥å¿—æ–¹æ³•"""
        def make_log_method(level):
            def log_method(msg, *args, **kwargs):
                if self._enable_logging:
                    getattr(self.logger, level)(msg, *args, **kwargs)
            return log_method
        
        return type('LogMethod', (), {
            'debug': make_log_method('debug'),
            'info': make_log_method('info'),
            'warning': make_log_method('warning'),
            'error': make_log_method('error'),
            'exception': make_log_method('exception')
        })

    async def test_channels(self, 
                          channels: List[Channel], 
                          progress_cb: Callable,
                          failed_urls: Set[str], 
                          white_list: Set[str]) -> None:
        """
        æ‰¹é‡æµ‹è¯•é¢‘é“ï¼ˆå®‰å…¨ç‰ˆæœ¬ï¼‰
        
        å‚æ•°:
            channels: é¢‘é“åˆ—è¡¨
            progress_cb: è¿›åº¦å›è°ƒå‡½æ•°
            failed_urls: å­˜å‚¨å¤±è´¥URLçš„é›†åˆ
            white_list: ç™½åå•é›†åˆ
        """
        self.total_count = len(channels)
        self.success_count = 0
        self.start_time = time.time()
        
        self.log.info(
            "â–¶ï¸ å¼€å§‹æµ‹é€Ÿ | æ€»æ•°: %d | å¹¶å‘: %d | å•IPæœ€å¤§é¢‘é“: %d | æœ€å¤§ä¸‹è½½é‡: %dKB",
            self.total_count, self.concurrency, self.max_channels_per_ip,
            self.max_download_size // 1024
        )

        # æ™ºèƒ½IPåˆ†ç»„
        ip_groups = self._group_channels_by_ip(channels, white_list)
        
        self.log.info(
            "ğŸ“Š IPåˆ†ç»„å®Œæˆ | æ€»ç»„æ•°: %d | æœ€å¤§ç»„: %d | å¹³å‡ç»„: %.1f",
            len(ip_groups), max(len(g) for g in ip_groups.values()), 
            sum(len(g) for g in ip_groups.values())/len(ip_groups)
        )

        # åˆ›å»ºè‡ªå®šä¹‰connector
        connector = aiohttp.TCPConnector(
            limit=self.concurrency,
            force_close=False,
            enable_cleanup_closed=True,
            ssl=False
        )

        try:
            async with aiohttp.ClientSession(
                connector=connector,
                timeout=aiohttp.ClientTimeout(total=self.timeout)
            ) as session:
                # åŠ¨æ€æ‰¹å¤„ç†
                batch_size = self._calculate_batch_size(len(ip_groups))
                tasks = []
                
                for ip, group in ip_groups.items():
                    if ip not in self.blocked_ips:
                        task = self._process_ip_group(
                            session, ip, group, progress_cb, failed_urls, white_list)
                        tasks.append(task)
                        
                        if len(tasks) >= batch_size:
                            await self._safe_gather(tasks)
                            progress_cb(len(tasks))
                            tasks = []
                
                if tasks:
                    await self._safe_gather(tasks)
                    progress_cb(len(tasks))
        except Exception as e:
            self.log.error("æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: %s", str(e))
            if "_abort" not in str(e):
                raise
        finally:
            await connector.close()
        
        elapsed = time.time() - self.start_time
        success_rate = (self.success_count / self.total_count) * 100 if self.total_count > 0 else 0
        self.log.info(
            "âœ… æµ‹é€Ÿå®Œæˆ | æˆåŠŸ: %d(%.1f%%) | å¤±è´¥: %d | å±è”½IP: %d | ç”¨æ—¶: %.1fs",
            self.success_count, success_rate,
            self.total_count - self.success_count,
            len(self.blocked_ips),
            elapsed
        )

    async def _safe_gather(self, tasks):
        """å®‰å…¨æ‰§è¡Œgatheræ“ä½œ"""
        try:
            await asyncio.gather(*tasks)
        except Exception as e:
            self.log.warning("æ‰¹å¤„ç†ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: %s", str(e))

    def _calculate_batch_size(self, total_groups: int) -> int:
        """åŠ¨æ€è®¡ç®—æ‰¹å¤„ç†å¤§å°"""
        if total_groups <= 100:
            return total_groups
        elif total_groups <= 1000:
            return 100
        return min(500, max(50, total_groups // 20))

    def _group_channels_by_ip(self, 
                            channels: List[Channel],
                            white_list: Set[str]) -> Dict[str, List[Channel]]:
        """
        æ”¹è¿›ç‰ˆIPåˆ†ç»„é€»è¾‘
        è¿”å›: { "ip_0": [ch1,ch2...], "ip_1": [...] }
        """
        groups = defaultdict(list)
        ip_counter = defaultdict(int)
        
        # ç™½åå•ç‹¬ç«‹åˆ†ç»„
        whitelist_group = [ch for ch in channels if self._is_in_white_list(ch, white_list)]
        if whitelist_group:
            groups["whitelist"] = whitelist_group
        
        # å¸¸è§„åˆ†ç»„
        for ch in channels:
            if self._is_in_white_list(ch, white_list):
                continue
                
            ip = self._extract_ip_from_url(ch.url)
            group_idx = ip_counter[ip] // self.max_channels_per_ip
            group_key = f"{ip}_{group_idx}"
            
            groups[group_key].append(ch)
            ip_counter[ip] += 1
            
            self.log.debug("IP %s é¢‘é“æ•°è¶…è¿‡ %dï¼Œåˆ›å»ºåˆ†ç»„ %s", 
                         ip, self.max_channels_per_ip, group_key)
        
        return groups

    async def _process_ip_group(self, 
                              session: aiohttp.ClientSession,
                              ip: str, 
                              channels: List[Channel],
                              progress_cb: Callable,
                              failed_urls: Set[str],
                              white_list: Set[str]) -> None:
        """å¤„ç†IPåˆ†ç»„ï¼ˆå¸¦åŠ¨æ€å†·å´ï¼‰"""
        # åŠ¨æ€å†·å´è®¡ç®—
        current_time = time.time()
        if ip in self.ip_cooldown:
            elapsed = current_time - self.ip_cooldown[ip]
            cool_down = max(0, self.min_ip_interval * (1 + len(channels)/self.max_channels_per_ip) - elapsed)
            if cool_down > 0:
                self.log.debug("â³ IP %s å†·å´ä¸­ (%.2fs)", ip, cool_down)
                await asyncio.sleep(cool_down)
        
        try:
            # åŠ¨æ€è°ƒæ•´ç»„å†…å¹¶å‘
            group_concurrency = max(1, min(
                self.concurrency,
                self.concurrency // (len(channels) // self.max_channels_per_ip + 1)
            ))
            group_semaphore = asyncio.BoundedSemaphore(group_concurrency)
            
            async def process_channel(channel):
                async with group_semaphore:
                    await self._test_single_channel(
                        session, channel, progress_cb, failed_urls, white_list)
            
            await self._safe_gather([process_channel(ch) for ch in channels])
            
            # æˆåŠŸåˆ™é‡ç½®å¤±è´¥è®¡æ•°
            if ip in self.failed_ips:
                del self.failed_ips[ip]
                
        except Exception as e:
            self.failed_ips[ip] += 1
            self.log.error("âŒ IPç»„ %s æµ‹è¯•å¼‚å¸¸: %s", ip, str(e))
            
            if self.failed_ips[ip] >= self.max_failures_per_ip:
                self.blocked_ips.add(ip)
                self.log.warning("ğŸ›‘ å±è”½IP %s (è¿ç»­å¤±è´¥ %d æ¬¡)", ip, self.failed_ips[ip])
        finally:
            self.ip_cooldown[ip] = time.time()

    async def _test_single_channel(self,
                                 session: aiohttp.ClientSession,
                                 channel: Channel,
                                 progress_cb: Callable,
                                 failed_urls: Set[str],
                                 white_list: Set[str]) -> None:
        """æµ‹è¯•å•ä¸ªé¢‘é“"""
        if self._is_in_white_list(channel, white_list):
            channel.status = 'online'
            self.log.debug("ğŸŸ¢ ç™½åå•è·³è¿‡ %s", channel.name)
            progress_cb()
            return

        async with self.semaphore:
            try:
                self.log.debug("ğŸ” å¼€å§‹æµ‹è¯• %s", channel.name)

                success, speed, latency = await self._unified_test(session, channel)
                
                if success:
                    self._handle_success(channel, speed, latency)
                else:
                    self._handle_failure(channel, failed_urls, speed, latency)
                    
            except Exception as e:
                self._handle_error(channel, failed_urls, e)
            finally:
                progress_cb()

    async def _unified_test(self,
                          session: aiohttp.ClientSession,
                          channel: Channel) -> Tuple[bool, float, float]:
        """ç»Ÿä¸€æµ‹è¯•æ–¹æ³•ï¼ˆæ”¯æŒUDP/HTTPåè®®ï¼‰"""
        try:
            headers = {'User-Agent': 'Mozilla/5.0'}
            is_udp = self._is_udp_url(channel.url)
            timeout_val = self.udp_timeout if is_udp else self.http_timeout
            timeout = aiohttp.ClientTimeout(total=timeout_val)
            
            # åè®®é˜ˆå€¼
            min_speed = self.min_udp_download_speed if is_udp else self.min_download_speed
            max_latency = self.max_udp_latency if is_udp else self.max_http_latency

            # é˜¶æ®µ1ï¼šå¿«é€ŸHEADè¯·æ±‚æµ‹å»¶è¿Ÿ
            latency_start = time.perf_counter()
            async with session.head(channel.url, headers=headers, timeout=timeout) as resp:
                latency = (time.perf_counter() - latency_start) * 1000
                if latency > max_latency or resp.status != 200:
                    return False, 0.0, latency

            # é˜¶æ®µ2ï¼šGETè¯·æ±‚æµ‹é€Ÿåº¦ï¼ˆå¤ç”¨è¿æ¥ï¼‰
            start = time.perf_counter()
            content_size = 0
            
            # ä½¿ç”¨iter_chunkedåˆ†å—è¯»å–ï¼Œé¿å…ä¸€æ¬¡æ€§åŠ è½½å¤§æ–‡ä»¶
            async with session.get(channel.url, headers=headers, timeout=timeout) as resp:
                async for chunk in resp.content.iter_chunked(1024 * 4):  # 4KB chunks
                    content_size += len(chunk)
                    # è¾¾åˆ°æœ€å¤§ä¸‹è½½é‡æ—¶æå‰ç»“æŸ
                    if content_size >= self.max_download_size:
                        break
                
                duration = time.perf_counter() - start
                speed = content_size / duration / 1024 if duration > 0 else 0
                return speed >= min_speed, speed, latency

        except asyncio.TimeoutError:
            return False, 0.0, 0.0
        except aiohttp.ClientError as e:
            return False, 0.0, 0.0
        except Exception as e:
            self.log.error("æµ‹è¯•é”™è¯¯ %s: %s", channel.url, str(e)[:100])
            return False, 0.0, 0.0

    def _handle_success(self,
                      channel: Channel,
                      speed: float,
                      latency: float) -> None:
        """å¤„ç†æˆåŠŸç»“æœ"""
        self.success_count += 1
        channel.status = 'online'
        channel.response_time = latency
        channel.download_speed = speed
        
        protocol = "UDP" if self._is_udp_url(channel.url) else "HTTP"
        self.log.info(
            "âœ… æˆåŠŸ | %-5s | %-30s | %6.1fKB/s | %4.0fms | %s",
            protocol, channel.name[:30], speed, latency,
            self._simplify_url(channel.url)
        )

    def _handle_failure(self,
                       channel: Channel,
                       failed_urls: Set[str],
                       speed: float,
                       latency: float) -> None:
        """å¤„ç†å¤±è´¥ç»“æœ"""
        failed_urls.add(channel.url)
        channel.status = 'offline'
        ip = self._extract_ip_from_url(channel.url)
        self.failed_ips[ip] += 1
        
        is_udp = self._is_udp_url(channel.url)
        reason = (
            "é€Ÿåº¦ä¸è¶³" if speed > 0 and speed < (
                self.min_udp_download_speed if is_udp else self.min_download_speed
            ) else
            "å»¶è¿Ÿè¿‡é«˜" if latency > (
                self.max_udp_latency if is_udp else self.max_http_latency
            ) else
            "è¿æ¥å¤±è´¥"
        )
        
        self.log.warning(
            "âŒ å¤±è´¥ | %-5s | %-30s | %6.1fKB/s | %4.0fms | %-8s | %s",
            "UDP" if is_udp else "HTTP",
            channel.name[:30], speed, latency, reason,
            self._simplify_url(channel.url)
        )

    def _handle_error(self,
                     channel: Channel,
                     failed_urls: Set[str],
                     error: Exception) -> None:
        """å¤„ç†å¼‚å¸¸"""
        failed_urls.add(channel.url)
        channel.status = 'offline'
        ip = self._extract_ip_from_url(channel.url)
        self.failed_ips[ip] += 1
        
        self.log.error(
            "â€¼ï¸ å¼‚å¸¸ | %-30s | %-20s | %s",
            channel.name[:30], str(error)[:20],
            self._simplify_url(channel.url)
        )

    def _is_udp_url(self, url: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºUDPåè®®URL"""
        url_lower = url.lower()
        return (url_lower.startswith(('udp://', 'rtp://')) or 
                bool(self.rtp_udp_pattern.search(url_lower)))

    def _extract_ip_from_url(self, url: str) -> str:
        """ä»URLæå–IPåœ°å€"""
        try:
            parsed = urlparse(url)
            netloc = parsed.netloc.split('@')[-1]
            if '[' in netloc and ']' in netloc:  # IPv6
                return netloc.split(']')[0] + ']'
            return netloc.split(':')[0]  # IPv4
        except:
            return "unknown"

    def _simplify_url(self, url: str) -> str:
        """ç®€åŒ–URLæ˜¾ç¤º"""
        return url[:100] + '...' if len(url) > 100 else url

    def _is_in_white_list(self,
                        channel: Channel,
                        white_list: Set[str]) -> bool:
        """æ£€æŸ¥æ˜¯å¦åœ¨ç™½åå•ä¸­"""
        if not white_list:
            return False
        return channel.name.lower() in white_list